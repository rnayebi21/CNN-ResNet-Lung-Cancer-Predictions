{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Splitting into Training and Testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPSnhgeEJ_MA"
      },
      "source": [
        "import random as random\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils import data\n",
        "%matplotlib inline\n",
        "\n",
        "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-kfgJGX-QZI",
        "outputId": "0c9719f2-72ad-4268-b4d1-dab3f5fd7869"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_root='/content/drive/My Drive/12th Grade 2020 - 2021/Senior Project/Project/Datasets'\n",
        "image_datasets = torchvision.datasets.ImageFolder(root=data_root, transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TJ_r9EwI_z5"
      },
      "source": [
        "img_dataloader = data.DataLoader(image_datasets)\n",
        "toPIL = transforms.ToPILImage()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUaa3LB2JIRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6599a75-02f8-429d-f12a-a56f333785c1"
      },
      "source": [
        "count = 0\n",
        "test = 0\n",
        "for img, label in img_dataloader:\n",
        "  count+=1\n",
        "  if count%200 == 0:\n",
        "    print(count)\n",
        "  if not label.equal(torch.tensor([0])):\n",
        "    print(\"final count: \", count)\n",
        "    test = img\n",
        "    break\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "400\n",
            "600\n",
            "800\n",
            "1000\n",
            "1200\n",
            "1400\n",
            "1600\n",
            "1800\n",
            "2000\n",
            "2200\n",
            "2400\n",
            "2600\n",
            "2800\n",
            "3000\n",
            "3200\n",
            "3400\n",
            "3600\n",
            "3800\n",
            "4000\n",
            "4200\n",
            "4400\n",
            "4600\n",
            "4800\n",
            "5000\n",
            "final count:  5001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXzQC4XBTOi1",
        "outputId": "ec2da5e7-7b46-4edf-fbf1-ce7508523a8a"
      },
      "source": [
        "ls \"/content/drive/My Drive/12th Grade 2020 - 2021/Senior Project/Project/SeparatedData/try\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mlung_aca\u001b[0m/  \u001b[01;34mlung_n\u001b[0m/  \u001b[01;34mlung_scc\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93t6z4kkYgz4"
      },
      "source": [
        "testing_access = torchvision.datasets.ImageFolder(root='/content/drive/My Drive/12th Grade 2020 - 2021/Senior Project/Project/SeparatedData/try', transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qvjjsr5ZweD"
      },
      "source": [
        "#**REAL DEAL HERE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spfHYu1najmL"
      },
      "source": [
        "def get_path(is_train, label, name):\n",
        "    path = F\"/content/drive/My Drive/12th Grade 2020 - 2021/Senior Project/Project/SeparatedData/try/{name}\"\n",
        "    if is_train:\n",
        "        if label.equal(torch.tensor([0])):\n",
        "            path = F\"/content/drive/My Drive/12th Grade 2020 - 2021/Senior Project/Project/SeparatedData/train/lung_aca/{name}\"\n",
        "        elif label.equal(torch.tensor([1])):\n",
        "            path = F\"/content/drive/My Drive/12th Grade 2020 - 2021/Senior Project/Project/SeparatedData/train/lung_n/{name}\"\n",
        "        elif label.equal(torch.tensor([2])):\n",
        "            path = F\"/content/drive/My Drive/12th Grade 2020 - 2021/Senior Project/Project/SeparatedData/train/lung_scc/{name}\"\n",
        "    else:\n",
        "        if label.equal(torch.tensor([0])):\n",
        "            path = F\"/content/drive/My Drive/12th Grade 2020 - 2021/Senior Project/Project/SeparatedData/test/lung_aca/{name}\"\n",
        "        elif label.equal(torch.tensor([1])):\n",
        "            path = F\"/content/drive/My Drive/12th Grade 2020 - 2021/Senior Project/Project/SeparatedData/test/lung_n/{name}\"\n",
        "        elif label.equal(torch.tensor([2])):\n",
        "            path = F\"/content/drive/My Drive/12th Grade 2020 - 2021/Senior Project/Project/SeparatedData/test/lung_scc/{name}\"      \n",
        "      \n",
        "    return path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFmyh-feiWAN",
        "outputId": "8de0b04f-d06c-4c63-ba7a-c32dae2623f6"
      },
      "source": [
        "percent = 0.2\n",
        "count = 0\n",
        "amt_imgs_in_train = 0\n",
        "amt_imgs_in_test = 0\n",
        "for img, label in img_dataloader:\n",
        "    name = \"img_\"+str(count)+\".jpeg\"\n",
        "    path = F\"/content/drive/My Drive/12th Grade 2020 - 2021/Senior Project/Project/SeparatedData/try/{name}\"\n",
        "    pil_img = toPIL(img[0])\n",
        "    if random.random() >= percent:\n",
        "        if amt_imgs_in_train == (int(len(image_datasets) * (1-percent)) + 1): # + 1 because of round off error\n",
        "            path = get_path(is_train=False, label=label, name=name)\n",
        "            amt_imgs_in_test+=1\n",
        "        else:\n",
        "            path = get_path(is_train=True, label=label, name=name)\n",
        "            amt_imgs_in_train+=1\n",
        "    else:\n",
        "        if amt_imgs_in_test == int(len(image_datasets) * percent):\n",
        "            path = get_path(is_train=True, label=label, name=name)\n",
        "            amt_imgs_in_train+=1\n",
        "        else:\n",
        "            path = get_path(is_train=False, label=label, name=name)\n",
        "            amt_imgs_in_test+=1\n",
        "        \n",
        "    pil_img.save(path)\n",
        "    if count%200 == 0:\n",
        "        print(count)\n",
        "    count+=1\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "200\n",
            "400\n",
            "600\n",
            "800\n",
            "1000\n",
            "1200\n",
            "1400\n",
            "1600\n",
            "1800\n",
            "2000\n",
            "2200\n",
            "2400\n",
            "2600\n",
            "2800\n",
            "3000\n",
            "3200\n",
            "3400\n",
            "3600\n",
            "3800\n",
            "4000\n",
            "4200\n",
            "4400\n",
            "4600\n",
            "4800\n",
            "5000\n",
            "5200\n",
            "5400\n",
            "5600\n",
            "5800\n",
            "6000\n",
            "6200\n",
            "6400\n",
            "6600\n",
            "6800\n",
            "7000\n",
            "7200\n",
            "7400\n",
            "7600\n",
            "7800\n",
            "8000\n",
            "8200\n",
            "8400\n",
            "8600\n",
            "8800\n",
            "9000\n",
            "9200\n",
            "9400\n",
            "9600\n",
            "9800\n",
            "10000\n",
            "10200\n",
            "10400\n",
            "10600\n",
            "10800\n",
            "11000\n",
            "11200\n",
            "11400\n",
            "11600\n",
            "11800\n",
            "12000\n",
            "12200\n",
            "12400\n",
            "12600\n",
            "12800\n",
            "13000\n",
            "13200\n",
            "13400\n",
            "13600\n",
            "13800\n",
            "14000\n",
            "14200\n",
            "14400\n",
            "14600\n",
            "14800\n",
            "15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfbfSl3eGqvz"
      },
      "source": [
        "note just printed out the count to see the progress being made"
      ]
    }
  ]
}